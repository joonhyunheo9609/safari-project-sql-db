# .github/workflows/sql-runner.yml
# SQLite ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ê´€ë¦¬í•˜ëŠ” GitHub Actions ì›Œí¬í”Œë¡œìš°

name: ğŸ—„ï¸ SQLite Database Runner

on:
  # Apps Scriptì—ì„œ ìˆ˜ë™ìœ¼ë¡œ íŠ¸ë¦¬ê±°
  workflow_dispatch:
    inputs:
      sql_query:
        description: 'SQL Query to execute'
        required: true
        type: string
      parameters:
        description: 'Query parameters (JSON array)'
        required: false
        default: '[]'
        type: string
      action_type:
        description: 'Type of action (query/update/init)'
        required: false
        default: 'query'
        type: string

  # ìŠ¤ì¼€ì¤„ëŸ¬ (ì„ íƒì‚¬í•­ - ë§¤ì¼ ìì •ì— ë°±ì—…)
  schedule:
    - cron: '0 0 * * *'  # ë§¤ì¼ UTC ìì •

  # Push ì´ë²¤íŠ¸ (db í´ë” ë³€ê²½ ì‹œ)
  push:
    paths:
      - 'database/**'
      - '.github/workflows/sql-runner.yml'

jobs:
  sqlite-operations:
    runs-on: ubuntu-latest
    
    steps:
    # 1. Repository ì²´í¬ì•„ì›ƒ
    - name: ğŸ“¥ Checkout Repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        fetch-depth: 0

    # 2. SQLite ì„¤ì¹˜ ë° ì„¤ì •
    - name: ğŸ—„ï¸ Setup SQLite
      run: |
        sudo apt-get update
        sudo apt-get install -y sqlite3
        sqlite3 --version

    # 3. ë°ì´í„°ë² ì´ìŠ¤ ë””ë ‰í† ë¦¬ ìƒì„±
    - name: ğŸ“ Create Database Directory
      run: |
        mkdir -p database
        mkdir -p results
        mkdir -p backups

    # 4. ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” (íŒŒì¼ì´ ì—†ëŠ” ê²½ìš°)
    - name: ğŸ”§ Initialize Database
      run: |
        if [ ! -f database/safari_project.db ]; then
          echo "Creating new SQLite database..."
          sqlite3 database/safari_project.db << 'EOF'
        
        -- Page Requests í…Œì´ë¸”
        CREATE TABLE IF NOT EXISTS page_requests (
          id INTEGER PRIMARY KEY AUTOINCREMENT,
          priority TEXT,
          status TEXT,
          title TEXT UNIQUE NOT NULL,
          category TEXT,
          requested_by TEXT,
          reference_url TEXT,
          date_requested DATETIME,
          date_scheduled DATETIME,
          assigned_to TEXT,
          date_completed DATETIME,
          notes TEXT,
          created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
          updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
        );

        -- Weekly Schedule í…Œì´ë¸”
        CREATE TABLE IF NOT EXISTS weekly_schedule (
          id INTEGER PRIMARY KEY AUTOINCREMENT,
          title TEXT NOT NULL,
          week_date DATE,
          scheduled_date DATETIME,
          assigned_to TEXT,
          priority TEXT,
          status TEXT,
          row_position INTEGER,
          column_position INTEGER,
          created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
          updated_at DATETIME DEFAULT CURRENT_TIMESTAMP,
          UNIQUE(title, week_date)
        );

        -- Sync Log í…Œì´ë¸”
        CREATE TABLE IF NOT EXISTS sync_log (
          id INTEGER PRIMARY KEY AUTOINCREMENT,
          timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
          action TEXT NOT NULL,
          table_name TEXT,
          title TEXT,
          details TEXT,
          success BOOLEAN DEFAULT TRUE
        );

        -- ì¸ë±ìŠ¤ ìƒì„±
        CREATE INDEX IF NOT EXISTS idx_page_requests_title ON page_requests(title);
        CREATE INDEX IF NOT EXISTS idx_page_requests_status ON page_requests(status);
        CREATE INDEX IF NOT EXISTS idx_weekly_schedule_title ON weekly_schedule(title);
        CREATE INDEX IF NOT EXISTS idx_sync_log_timestamp ON sync_log(timestamp);

        -- ì´ˆê¸° ë¡œê·¸ ì¶”ê°€
        INSERT INTO sync_log (action, table_name, details) 
        VALUES ('database_init', 'system', 'Database initialized via GitHub Actions');

        EOF
          echo "âœ… Database initialized successfully"
        else
          echo "ğŸ“Š Database already exists"
        fi

    # 5. SQL ì¿¼ë¦¬ ì‹¤í–‰ (Apps Scriptì—ì„œ íŠ¸ë¦¬ê±°ëœ ê²½ìš°)
    - name: ğŸ” Execute SQL Query
      if: github.event.inputs.sql_query != ''
      run: |
        echo "Executing SQL Query: ${{ github.event.inputs.sql_query }}"
        
        # íŒŒë¼ë¯¸í„° ì²˜ë¦¬
        PARAMETERS='${{ github.event.inputs.parameters }}'
        ACTION_TYPE='${{ github.event.inputs.action_type }}'
        
        # ê²°ê³¼ íŒŒì¼ ê²½ë¡œ
        RESULT_FILE="results/latest_query_result.json"
        
        # SQL ì¿¼ë¦¬ ì‹¤í–‰ ë° ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì €ì¥
        echo "Starting SQL execution..."
        
        # SQLiteì—ì„œ JSON í˜•íƒœë¡œ ê²°ê³¼ ì¶”ì¶œí•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
        cat > execute_query.py << 'EOF'
        import sqlite3
        import json
        import sys
        from datetime import datetime

        def execute_query(db_path, query, parameters_json):
            try:
                conn = sqlite3.connect(db_path)
                conn.row_factory = sqlite3.Row  # ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ê²°ê³¼ ë°˜í™˜
                cursor = conn.cursor()
                
                # íŒŒë¼ë¯¸í„° íŒŒì‹±
                parameters = json.loads(parameters_json) if parameters_json else []
                
                # ì¿¼ë¦¬ ì‹¤í–‰
                if parameters:
                    cursor.execute(query, parameters)
                else:
                    cursor.execute(query)
                
                # ê²°ê³¼ ì²˜ë¦¬
                if query.strip().upper().startswith('SELECT'):
                    # SELECT ì¿¼ë¦¬ - ê²°ê³¼ ë°˜í™˜
                    rows = cursor.fetchall()
                    result = [dict(row) for row in rows]
                else:
                    # INSERT/UPDATE/DELETE - ì˜í–¥ë°›ì€ í–‰ ìˆ˜ ë°˜í™˜
                    conn.commit()
                    result = {"affected_rows": cursor.rowcount, "lastrowid": cursor.lastrowid}
                
                conn.close()
                
                # ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
                output = {
                    "success": True,
                    "result": result,
                    "query": query,
                    "parameters": parameters,
                    "timestamp": datetime.now().isoformat(),
                    "row_count": len(result) if isinstance(result, list) else 1
                }
                
                with open("results/latest_query_result.json", "w") as f:
                    json.dump(output, f, indent=2)
                
                print(f"âœ… Query executed successfully. Results saved to JSON.")
                print(f"ğŸ“Š Rows affected/returned: {len(result) if isinstance(result, list) else result.get('affected_rows', 0)}")
                
            except Exception as e:
                # ì˜¤ë¥˜ ê²°ê³¼ ì €ì¥
                error_output = {
                    "success": False,
                    "error": str(e),
                    "query": query,
                    "parameters": parameters if 'parameters' in locals() else [],
                    "timestamp": datetime.now().isoformat()
                }
                
                with open("results/latest_query_result.json", "w") as f:
                    json.dump(error_output, f, indent=2)
                
                print(f"âŒ Query execution failed: {e}")
                sys.exit(1)

        if __name__ == "__main__":
            query = sys.argv[1]
            parameters = sys.argv[2] if len(sys.argv) > 2 else "[]"
            execute_query("database/safari_project.db", query, parameters)
        EOF
        
        # Python ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
        python3 execute_query.py "${{ github.event.inputs.sql_query }}" "${{ github.event.inputs.parameters }}"

    # 6. ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… (ë§¤ì¼ ìŠ¤ì¼€ì¤„ ë˜ëŠ” ìˆ˜ë™ ì‹¤í–‰ ì‹œ)
    - name: ğŸ’¾ Backup Database
      if: github.event_name == 'schedule' || github.event.inputs.action_type == 'backup'
      run: |
        # ë°±ì—… íŒŒì¼ëª…ì— ë‚ ì§œ í¬í•¨
        BACKUP_DATE=$(date +%Y%m%d_%H%M%S)
        BACKUP_FILE="backups/safari_project_${BACKUP_DATE}.db"
        
        if [ -f database/safari_project.db ]; then
          cp database/safari_project.db "$BACKUP_FILE"
          
          # ì••ì¶•í•˜ì—¬ ìš©ëŸ‰ ì ˆì•½
          gzip "$BACKUP_FILE"
          
          echo "âœ… Database backup created: ${BACKUP_FILE}.gz"
          
          # 30ì¼ ì´ìƒ ëœ ë°±ì—… íŒŒì¼ ì‚­ì œ
          find backups/ -name "*.gz" -mtime +30 -delete
          echo "ğŸ§¹ Old backups cleaned up"
          
          # ë°±ì—… ë¡œê·¸ ì¶”ê°€
          sqlite3 database/safari_project.db << EOF
          INSERT INTO sync_log (action, table_name, details) 
          VALUES ('database_backup', 'system', 'Database backup created: ${BACKUP_FILE}.gz');
        EOF
        else
          echo "âš ï¸ Database file not found for backup"
        fi

    # 7. ë°ì´í„°ë² ì´ìŠ¤ í†µê³„ ìƒì„±
    - name: ğŸ“Š Generate Database Statistics
      run: |
        echo "Generating database statistics..."
        
        cat > generate_stats.py << 'EOF'
        import sqlite3
        import json
        from datetime import datetime

        def generate_stats():
            conn = sqlite3.connect("database/safari_project.db")
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()
            
            stats = {
                "generated_at": datetime.now().isoformat(),
                "database_info": {},
                "table_stats": {},
                "status_breakdown": [],
                "priority_breakdown": [],
                "recent_activity": []
            }
            
            try:
                # ë°ì´í„°ë² ì´ìŠ¤ ê¸°ë³¸ ì •ë³´
                cursor.execute("SELECT COUNT(*) as total FROM page_requests")
                stats["database_info"]["total_page_requests"] = cursor.fetchone()[0]
                
                cursor.execute("SELECT COUNT(*) as total FROM weekly_schedule") 
                stats["database_info"]["total_weekly_items"] = cursor.fetchone()[0]
                
                cursor.execute("SELECT COUNT(*) as total FROM sync_log")
                stats["database_info"]["total_log_entries"] = cursor.fetchone()[0]
                
                # ìƒíƒœë³„ í†µê³„
                cursor.execute("""
                    SELECT status, COUNT(*) as count 
                    FROM page_requests 
                    WHERE status IS NOT NULL 
                    GROUP BY status 
                    ORDER BY count DESC
                """)
                stats["status_breakdown"] = [dict(row) for row in cursor.fetchall()]
                
                # ìš°ì„ ìˆœìœ„ë³„ í†µê³„
                cursor.execute("""
                    SELECT priority, COUNT(*) as count 
                    FROM page_requests 
                    WHERE priority IS NOT NULL 
                    GROUP BY priority 
                    ORDER BY count DESC
                """)
                stats["priority_breakdown"] = [dict(row) for row in cursor.fetchall()]
                
                # ìµœê·¼ í™œë™
                cursor.execute("""
                    SELECT action, table_name, details, timestamp
                    FROM sync_log 
                    ORDER BY timestamp DESC 
                    LIMIT 10
                """)
                stats["recent_activity"] = [dict(row) for row in cursor.fetchall()]
                
                # í…Œì´ë¸”ë³„ í†µê³„
                tables = ["page_requests", "weekly_schedule", "sync_log"]
                for table in tables:
                    cursor.execute(f"SELECT COUNT(*) as count FROM {table}")
                    count = cursor.fetchone()[0]
                    
                    cursor.execute(f"SELECT name FROM sqlite_master WHERE type='table' AND name='{table}'")
                    exists = cursor.fetchone() is not None
                    
                    stats["table_stats"][table] = {
                        "exists": exists,
                        "row_count": count
                    }
                
            except Exception as e:
                stats["error"] = str(e)
            
            finally:
                conn.close()
            
            # í†µê³„ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
            with open("results/database_stats.json", "w") as f:
                json.dump(stats, f, indent=2)
            
            print("ğŸ“Š Database statistics generated successfully")

        generate_stats()
        EOF
        
        python3 generate_stats.py

    # 8. ë³€ê²½ì‚¬í•­ ì»¤ë°‹ ë° í‘¸ì‹œ
    - name: ğŸ’¾ Commit and Push Changes
      run: |
        # Git ì„¤ì •
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        
        # ë³€ê²½ì‚¬í•­ í™•ì¸
        if [ -n "$(git status --porcelain)" ]; then
          echo "Changes detected, committing..."
          
          git add database/ results/ backups/
          
          # ì»¤ë°‹ ë©”ì‹œì§€ ìƒì„±
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            COMMIT_MSG="ğŸ”„ SQL query executed via Apps Script"
          elif [ "${{ github.event_name }}" = "schedule" ]; then
            COMMIT_MSG="ğŸ’¾ Scheduled database backup and stats update"
          else
            COMMIT_MSG="ğŸ“Š Database files updated"
          fi
          
          git commit -m "$COMMIT_MSG" -m "Automated commit from GitHub Actions"
          git push
          
          echo "âœ… Changes committed and pushed successfully"
        else
          echo "â„¹ï¸ No changes to commit"
        fi

    # 9. ì‘ì—… ì™„ë£Œ ì•Œë¦¼
    - name: ğŸ‰ Job Summary
      run: |
        echo "## ğŸ—„ï¸ SQLite Database Operations Complete" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [ -f "results/latest_query_result.json" ]; then
          echo "### ğŸ“Š Query Results" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`json" >> $GITHUB_STEP_SUMMARY
          head -20 results/latest_query_result.json >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
        fi
        
        if [ -f "results/database_stats.json" ]; then
          echo "### ğŸ“ˆ Database Statistics" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`json" >> $GITHUB_STEP_SUMMARY
          head -20 results/database_stats.json >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "### â° Execution Time" >> $GITHUB_STEP_SUMMARY
        echo "- Started: $(date -u)" >> $GITHUB_STEP_SUMMARY
        echo "- Workflow: ${{ github.workflow }}" >> $GITHUB_STEP_SUMMARY
        echo "- Trigger: ${{ github.event_name }}" >> $GITHUB_STEP_SUMMARY
        
        echo "âœ… All database operations completed successfully!"
